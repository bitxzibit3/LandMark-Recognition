{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VrHMg1kovn6n"
   },
   "source": [
    "## Установка и импорт модулей "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "mQlRyIIUeZCD"
   },
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "import PIL\n",
    "import sys\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import wandb\n",
    "\n",
    "\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from IPython.display import clear_output\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms as tf\n",
    "from torchvision.datasets import DatasetFolder\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# if not os.path.exists('./drive'):\n",
    "#     drive.mount('./drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uG61REZqesZs",
    "outputId": "c680e034-17de-491e-f017-bee65f18efbd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘./models’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "# if not os.path.exists('/root/.kaggle/kaggle.json'):\n",
    "#     !mkdir /root/.kaggle\n",
    "#     !cp ./drive/MyDrive/kaggle.json /root/.kaggle/kaggle.json\n",
    "#     !kaggle datasets download -d andreybeyn/qudata-gembed-landmarks-210\n",
    "#     !unzip -q qudata-gembed-landmarks-210.zip\n",
    "\n",
    "!mkdir ./models ./models/models ./models/desc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "id": "ak-wNNv1fMs6",
    "outputId": "8392f904-7b2d-4079-a05a-8214f8995e7f"
   },
   "outputs": [],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "id": "QyxHg2A9gaH5",
    "outputId": "40fae9ba-0523-430b-d62d-a234d888ec09"
   },
   "outputs": [],
   "source": [
    "run = wandb.init(\n",
    "    project = 'ml_landmarks',\n",
    "    entity = 'ml_landmarks',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fbL0U5EtcV-6"
   },
   "source": [
    "# Пайплайн примерно такой:\n",
    "\n",
    "\n",
    "*   Обрабатываем данные:\n",
    "\n",
    "    * Считываем данные, перегоняем в тензоры\n",
    "\n",
    "    * Мб делаем нормализацию (пока нет)\n",
    "\n",
    "    * Разбиваем на тренировочную/валидационную\n",
    "\n",
    "*   Пишем сетки: пробуем менять архитектуру, если совсем голяк - меняем предобработку.\n",
    "\n",
    "*   Попробовать сделать ансамбли: бэггинг!, бустинг.\n",
    "\n",
    "*   Оценивать будем `F1`, скорее всего.\n",
    "\n",
    "*   Если все совсем совсем плохо:\n",
    "\n",
    "    * Пробовать более сильные ансамбли. Если тут голяк - пробовать еще:)\n",
    "    \n",
    "    * Будем пробовать аугментацию, потому что картинок реально мало\n",
    "    \n",
    "    * Можно будет попробовать найти похожую сетку (похожую, исходя из поставленной задачи), и попробовать её зафайнтьюнить.\n",
    "    \n",
    "    * Брать другой датасет. Есть сразу проблемы: они в большинстве своем неразмечены (те, которые я находил).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZBJY1ezZXc_k"
   },
   "source": [
    "## Чтение данных\n",
    "\n",
    "Тут я попробовал поиграть с вариантами хранения данных. Где то считывал данные, и хранил уже обработанные тензоры, где то считывал данные, и обрабатывал только при необходимости. Также использовал класс, встроенный в `torchvision`. В конце привел сравнение работы всех классов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MOmvaLsLVEAy"
   },
   "source": [
    "В датасете есть черно-белые фотографии, и фотографии, в которых 4 канала, а не 3 по стандарту. Таких картинок немного, поэтому удалим их."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vD3XN3wd_Wch",
    "outputId": "5b45bf37-fcb2-442c-b398-c37c07545573"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files: 10515\n",
      "Deleted files: 19\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_path = './data/landmarks/'\n",
    "\n",
    "# Get all filepaths\n",
    "all_files = set()\n",
    "labels = []\n",
    "for path, dirs, files in os.walk(init_path):\n",
    "    if dirs == []:\n",
    "        for file_ in files:\n",
    "            filepath = '/'.join([path, file_])\n",
    "            all_files.add(filepath)\n",
    "    else:\n",
    "        labels.extend(dirs)\n",
    "\n",
    "# Filtering\n",
    "supported_types = ('RGB')\n",
    "\n",
    "incorrect_files = set()\n",
    "for filename in all_files:\n",
    "    img = PIL.Image.open(filename)\n",
    "    if img.mode not in supported_types:\n",
    "        incorrect_files.add(filename)\n",
    "    del img\n",
    "\n",
    "all_files = list(all_files - incorrect_files)\n",
    "print('\\n'.join([f'All files: {len(all_files)}',\n",
    "                 f'Deleted files: {len(incorrect_files)}']))\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SnSm8eSra48Z"
   },
   "source": [
    "### `FastDataset`\n",
    "Тут я сделал класс датасета с быстрым доступом.\n",
    "\n",
    "Мы сразу по названию файла обрезаем её, делаем из картинки тензор, запоминаем его, потом получаем к нему доступ просто по индексу, не делая никакой предобработки.\n",
    "\n",
    "+: Быстро бегаем\n",
    "\n",
    "-: Долгая инициализация\n",
    "\n",
    "-: В теории, может сожрать всю память"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lCHpJcJcGacG"
   },
   "outputs": [],
   "source": [
    "class FastDataset(Dataset):\n",
    "    def __init__(self, files, mode='train',\n",
    "                 transform=None,\n",
    "                 image_shape=(200, 200)):\n",
    "\n",
    "        \"\"\"\n",
    "        mode - train/valid/test\n",
    "        files - list with paths to files\n",
    "        transform - processing of file\n",
    "        image_shape - shape of result tensor\n",
    "        \"\"\"\n",
    "\n",
    "        self.mode = mode\n",
    "        self.image_shape = image_shape\n",
    "        self.transform = transform if transform \\\n",
    "            else tf.Compose([tf.Resize(image_shape), tf.PILToTensor()])\n",
    "        self.x = []\n",
    "        self.y = []\n",
    "\n",
    "        self.check_mode = self.mode in ('train', 'valid')\n",
    "\n",
    "        labels = list(set([self.get_label(filename) for filename in files]))\n",
    "        self.le = LabelEncoder()\n",
    "        self.le.fit(labels)\n",
    "\n",
    "        # Saving tensors from PIL.Image\n",
    "        for path in files:\n",
    "            label = path.split('/')[-2]\n",
    "            tensor = self.get_sample(path)\n",
    "            self.x.append(tensor / 255)\n",
    "            self.y.append(label)\n",
    "\n",
    "        self._len = len(self.x)\n",
    "\n",
    "    def get_sample(self, filepath):\n",
    "        with PIL.Image.open(filepath) as image:\n",
    "            image = PIL.Image.open(filepath)\n",
    "            tensor = self.transform(image)\n",
    "        return tensor\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Returns Tensor, str (optional)\n",
    "        \"\"\"\n",
    "        if self.check_mode:\n",
    "            y = self.le.transform([self.y[idx]])\n",
    "            return self.x[idx], y[0]\n",
    "        else:\n",
    "            return self.x[idx]\n",
    "\n",
    "    def decode(self, num_label):\n",
    "        return self.le.inverse_transform([num_label])[0]\n",
    "\n",
    "    def train_valid_split(self, train_size=0.9):\n",
    "        \"\"\"\n",
    "        Uniform split of files.\n",
    "\n",
    "        Returns two datasets: train_dataset and valid_dataset\n",
    "        \"\"\"\n",
    "\n",
    "        def handle_one_class(label):\n",
    "            file_list = get_class_samples(label)\n",
    "            train_set, valid_set = train_test_split(tuple(file_list),\n",
    "                                                    train_size=train_size)\n",
    "            return train_set, valid_set\n",
    "\n",
    "        def get_class_samples(label):\n",
    "            return set([filename\n",
    "                        for filename in self.files if label in filename.split('/')])\n",
    "\n",
    "        train_list = []\n",
    "        valid_list = []\n",
    "        labels = self.le.classes_\n",
    "\n",
    "        for label in labels:\n",
    "            cur_train_list, cur_valid_list = handle_one_class(label)\n",
    "            train_list.extend(cur_train_list)\n",
    "            valid_list.extend(cur_valid_list)\n",
    "\n",
    "        train_ds = FastDataset(mode='train',\n",
    "                               image_shape=self.image_shape,\n",
    "                               files=train_list)\n",
    "\n",
    "        valid_ds = FastDataset(mode='valid',\n",
    "                               image_shape=self.image_shape,\n",
    "                               files=valid_list)\n",
    "        return train_ds, valid_ds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8dyv0_7gbQyx"
   },
   "source": [
    "### `CustomDataset`\n",
    "\n",
    "Это тоже класс датасета, но с медленным доступом. Здесь мы запоминаем все пути до картинок, потом при получении по индексу делаем предобработку, типа ресайз и перегоняем в тензор.\n",
    "\n",
    "+: Жрет немного памяти (ну во всяком случае меньше, чем `FastDataset`)\n",
    "\n",
    "+: Быстрая иницилазция\n",
    "\n",
    "-: Долго бегает"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XeU6HdblouLU"
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, files, mode='train',\n",
    "                 transform=None,\n",
    "                 image_shape=(200, 200)):\n",
    "\n",
    "        \"\"\"\n",
    "        mode - train/valid/test\n",
    "        files - list/set with filepaths\n",
    "        transform - processing of file\n",
    "        image_shape - shape of result tensor\n",
    "        \"\"\"\n",
    "\n",
    "        self.mode = mode\n",
    "        self.transform = transform\n",
    "        self.image_shape = image_shape\n",
    "        self.files = files\n",
    "\n",
    "        self.check_mode = self.mode in ('train', 'test')\n",
    "\n",
    "        labels = list(set([self.get_label(filename) for filename in files]))\n",
    "        self.le = LabelEncoder()\n",
    "        self.le.fit(labels)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def default_transform(self, img):\n",
    "        \"\"\"\n",
    "        Make image resizing, and converting to tensor\n",
    "        \"\"\"\n",
    "        transform = tf.Compose([\n",
    "            tf.Resize(self.image_shape),\n",
    "            tf.PILToTensor()\n",
    "        ])\n",
    "        return transform(img)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.files[idx]\n",
    "        with PIL.Image.open(path) as img:\n",
    "            if self.transform:\n",
    "                tensor = self.transform(img)\n",
    "            else:\n",
    "                tensor = self.default_transform(img)\n",
    "\n",
    "        if self.check_mode:\n",
    "            label = self.get_label(idx)\n",
    "            return tensor, self.le.transform([label])[0]\n",
    "        else:\n",
    "            return tensor\n",
    "\n",
    "    def get_label(self, idx):\n",
    "        assert self.check_mode, \\\n",
    "            'It is not possible to get label'\n",
    "        path = self.files[idx]\n",
    "        return path.split('/')[2]\n",
    "\n",
    "    def decode(self, num_label):\n",
    "        return self.le.inverse_transform([num_label])[0]\n",
    "\n",
    "    def train_valid_split(self, train_size=0.9):\n",
    "        \"\"\"\n",
    "        Uniform split of files.\n",
    "\n",
    "        Returns two datasets: train_dataset and valid_dataset (augmentations = [None])\n",
    "        \"\"\"\n",
    "\n",
    "        def handle_one_class(label):\n",
    "            file_list = get_class_samples(label)\n",
    "            train_set, valid_set = train_test_split(tuple(file_list),\n",
    "                                                    train_size=train_size)\n",
    "            return train_set, valid_set\n",
    "\n",
    "        def get_class_samples(label):\n",
    "            return set([filename\n",
    "                        for filename in self.files if label in filename.split('/')])\n",
    "\n",
    "        train_list = []\n",
    "        valid_list = []\n",
    "        labels = self.le.classes_\n",
    "\n",
    "        for label in labels:\n",
    "            cur_train_list, cur_valid_list = handle_one_class(label)\n",
    "            train_list.extend(cur_train_list)\n",
    "            valid_list.extend(cur_valid_list)\n",
    "\n",
    "        train_ds = CustomDataset(mode='train',\n",
    "                                 image_shape=self.image_shape,\n",
    "                                 files=train_list)\n",
    "\n",
    "        valid_ds = CustomDataset(mode='valid',\n",
    "                                 image_shape=self.image_shape,\n",
    "                                 files=valid_list)\n",
    "        return train_ds, valid_ds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lhrc_O1H6wGT"
   },
   "source": [
    "### `AugmentedFastDataset`\n",
    "\n",
    "Версия `FastDataset`, дополненная аугментациями"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8r2y-MkNdAyv"
   },
   "outputs": [],
   "source": [
    "class AugmentedFastDataset(Dataset):\n",
    "    def __init__(self, files, mode='train',\n",
    "                 transform=None, augmentate = True,\n",
    "                 image_shape=(200, 200)):\n",
    "        \"\"\"\n",
    "        files - list with paths to files\n",
    "        mode - train/valid/test\n",
    "        transform - processing of file\n",
    "        image_shape - shape of result tensor\n",
    "        \"\"\"\n",
    "\n",
    "        self.mode = mode\n",
    "        self.image_shape = image_shape\n",
    "        self.transform = transform if transform \\\n",
    "            else tf.Compose([tf.Resize(image_shape), tf.PILToTensor()])\n",
    "\n",
    "        self.x = []\n",
    "        self.y = []\n",
    "\n",
    "        self.check_mode = self.mode in ('train', 'valid')\n",
    "        self._len = len(files)\n",
    "\n",
    "        labels = list(set([self.get_label(filename) for filename in files]))\n",
    "        self.le = LabelEncoder()\n",
    "        self.le.fit(labels)\n",
    "\n",
    "        self.augmentations = (\n",
    "            None,\n",
    "            tf.ColorJitter(brightness=0.3,\n",
    "                           contrast=0.3,\n",
    "                           saturation=0.3),\n",
    "            tf.RandomPosterize(bits=2, p=1),\n",
    "            tf.RandomAdjustSharpness(sharpness_factor=2,\n",
    "                                     p=1),\n",
    "            tf.RandomEqualize(p=1),\n",
    "            tf.RandomRotation(degrees=(-20, 20)),\n",
    "            tf.RandomHorizontalFlip(p=1)\n",
    "        )\n",
    "\n",
    "        self.augmentations_amount = len(self.augmentations)\n",
    "\n",
    "        # Saving tensors from PIL.Image\n",
    "        for path in files:\n",
    "            label = path.split('/')[-2]\n",
    "            tensor = self.get_sample(path)\n",
    "            if augmentate:\n",
    "                augmentations = self.get_augmented_samples(tensor)\n",
    "                self.x.extend(augmentations)\n",
    "                self.y.extend([label] * self.augmentations_amount)\n",
    "            else:\n",
    "                self.x.append(tensor)\n",
    "                self.y.append(label)\n",
    "\n",
    "    def get_sample(self, filepath):\n",
    "        with PIL.Image.open(filepath) as image:\n",
    "            image = PIL.Image.open(filepath)\n",
    "            tensor = self.transform(image)\n",
    "        return tensor\n",
    "\n",
    "    def get_label(self, path):\n",
    "        assert self.check_mode, \\\n",
    "            'It is not possible to get label'\n",
    "        return path.split('/')[-2]\n",
    "\n",
    "    def get_augmented_samples(self, tensor):\n",
    "        answer = [tensor / 255]\n",
    "        answer.extend(\n",
    "            [augmentation(tensor) / 255\n",
    "             for augmentation in self.augmentations if augmentation]\n",
    "        )\n",
    "        return answer\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._len * self.augmentations_amount\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Returns Tensor, str (optional)\n",
    "        \"\"\"\n",
    "        if self.check_mode:\n",
    "            y = self.le.transform([self.y[idx]])\n",
    "            return self.x[idx], y[0]\n",
    "        else:\n",
    "            return self.x[idx]\n",
    "\n",
    "    def decode(self, num_label):\n",
    "        return self.le.inverse_transform([num_label])[0]\n",
    "\n",
    "    def train_valid_split(self, train_size=0.9):\n",
    "        \"\"\"\n",
    "        Uniform split of files.\n",
    "\n",
    "        Returns two datasets: train_dataset and valid_dataset (augmentations = [None])\n",
    "        \"\"\"\n",
    "\n",
    "        def handle_one_class(label):\n",
    "            file_list = get_class_samples(label)\n",
    "            train_set, valid_set = train_test_split(tuple(file_list),\n",
    "                                                    train_size=train_size)\n",
    "            return train_set, valid_set\n",
    "\n",
    "        def get_class_samples(label):\n",
    "            return set([filename\n",
    "                        for filename in self.files if label in filename[0].split('/')])\n",
    "\n",
    "        train_list = []\n",
    "        valid_list = []\n",
    "        labels = self.le.classes_\n",
    "\n",
    "        for label in labels:\n",
    "            cur_train_list, cur_valid_list = handle_one_class(label)\n",
    "            train_list.extend(cur_train_list)\n",
    "            valid_list.extend(cur_valid_list)\n",
    "\n",
    "        train_ds = AugmentedFastDataset(mode='train',\n",
    "                                        image_shape=self.image_shape,\n",
    "                                        files=train_list,\n",
    "                                        augmentate=False)\n",
    "        train_ds.augmentations = self.augmentations\n",
    "\n",
    "        valid_ds = AugmentedFastDataset(mode='valid',\n",
    "                                        image_shape=self.image_shape,\n",
    "                                        files=valid_list,\n",
    "                                        augmentate=False)\n",
    "        valid_ds.augmentations = self.augmentations\n",
    "        return train_ds, valid_ds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "62u_hQUT7Dvb"
   },
   "source": [
    "### `AugemntedCustomDataset`\n",
    "\n",
    "Версия `CustomDataset`, дополненная аугментациями"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_nDBuDhHfcLM"
   },
   "outputs": [],
   "source": [
    "class AugmentedCustomDataset(Dataset):\n",
    "    def __init__(self, files, mode='train',\n",
    "                 transform=None,\n",
    "                 image_shape=(200, 200), augmentations=None):\n",
    "        \"\"\"\n",
    "        mode - train/valid/test\n",
    "        files - list/set with filepaths\n",
    "        labels - list with all possible namelabels\n",
    "        transform - processing of file\n",
    "        image_shape - shape of result tensor\n",
    "        \"\"\"\n",
    "        self.mode = mode\n",
    "        self.transform = transform\n",
    "        self.image_shape = image_shape\n",
    "\n",
    "        self.check_mode = self.mode in ('train', 'valid')\n",
    "\n",
    "        labels = list(set([self.get_label(filename) for filename in files]))\n",
    "        self.le = LabelEncoder()\n",
    "        self.le.fit(labels)\n",
    "\n",
    "        # Initialize augmentation options\n",
    "        if augmentations:\n",
    "            self.augmentations = augmentations\n",
    "        else:\n",
    "            self.augmentations = [\n",
    "                None,\n",
    "                tf.ColorJitter(brightness=0.3,\n",
    "                               contrast=0.3,\n",
    "                               saturation=0.3),\n",
    "                tf.RandomPosterize(bits=2, p=1),\n",
    "                tf.RandomAdjustSharpness(sharpness_factor=2,\n",
    "                                         p=1),\n",
    "                tf.RandomEqualize(p=1),\n",
    "                tf.RandomRotation(degrees=(-20, 20)),\n",
    "                tf.RandomHorizontalFlip(p=1)\n",
    "            ]\n",
    "        self.augmentations_amount = len(self.augmentations)\n",
    "        if self.augmentations == [None]:\n",
    "            self.files = files\n",
    "\n",
    "        else:\n",
    "            self.files = []\n",
    "            for filename in files:\n",
    "                augmented_filenames = [(filename, i)\n",
    "                                       for i in range(self.augmentations_amount)]\n",
    "                self.files.extend(augmented_filenames)\n",
    "\n",
    "        self._len = len(self.files)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._len\n",
    "\n",
    "    def default_transform(self, img):\n",
    "        \"\"\"\n",
    "        Make image resizing, and converting to tensor\n",
    "        \"\"\"\n",
    "        transform = tf.Compose([\n",
    "            tf.Resize(self.image_shape),\n",
    "            tf.PILToTensor()\n",
    "        ])\n",
    "        return transform(img)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Find path to file depending on idx\n",
    "        filename, augment_idx = self.files[idx]\n",
    "        augment = self.augmentations[augment_idx]\n",
    "        with PIL.Image.open(filename) as img:\n",
    "            if self.transform:\n",
    "                tensor = self.transform(img)\n",
    "            else:\n",
    "                tensor = self.default_transform(img)\n",
    "\n",
    "            if augment:\n",
    "                tensor = augment(tensor)\n",
    "\n",
    "            tensor = tensor / 255\n",
    "\n",
    "        if self.check_mode:\n",
    "            label = self.get_label(filename)\n",
    "            return tensor, self.encode(label)\n",
    "        else:\n",
    "            return tensor\n",
    "\n",
    "    def get_label(self, path):\n",
    "        assert self.check_mode, \\\n",
    "            'It is not possible to get label'\n",
    "        return path.split('/')[-2]\n",
    "\n",
    "    def encode(self, str_label):\n",
    "        return self.le.transform([str_label])[0]\n",
    "\n",
    "    def decode(self, num_label):\n",
    "        return self.le.inverse_transform([num_label])[0]\n",
    "\n",
    "    def get_augmented_samples(self, idx):\n",
    "        begin_idx = idx * self.augmentations_amount\n",
    "        return [self[begin_idx + i][0] for i in range(self.augmentations_amount)]\n",
    "\n",
    "    def draw_augmented_samples(self, idx):\n",
    "        samples = self.get_augmented_samples(idx)\n",
    "        plt.figure(figsize=(20, 20))\n",
    "        for i, sample in enumerate(samples):\n",
    "            plt.subplot(1, len(samples), i + 1)\n",
    "            plt.imshow(sample.permute(1, 2, 0))\n",
    "\n",
    "    def train_valid_split(self, train_size=0.9):\n",
    "        \"\"\"\n",
    "        Uniform split of files.\n",
    "\n",
    "        Returns two datasets: train_dataset and valid_dataset (augmentations = [None])\n",
    "        \"\"\"\n",
    "\n",
    "        def handle_one_class(label):\n",
    "            file_list = get_class_samples(label)\n",
    "            train_set, valid_set = train_test_split(tuple(file_list),\n",
    "                                                    train_size=train_size)\n",
    "            return train_set, valid_set\n",
    "\n",
    "        def get_class_samples(label):\n",
    "            return set([filename\n",
    "                        for filename in self.files if label in filename[0].split('/')])\n",
    "\n",
    "        train_list = []\n",
    "        valid_list = []\n",
    "        labels = self.le.classes_\n",
    "\n",
    "        for label in labels:\n",
    "            cur_train_list, cur_valid_list = handle_one_class(label)\n",
    "            train_list.extend(cur_train_list)\n",
    "            valid_list.extend(cur_valid_list)\n",
    "\n",
    "        train_ds = AugmentedCustomDataset(mode='train',\n",
    "                                          image_shape=self.image_shape,\n",
    "                                          files=train_list,\n",
    "                                          augmentations=[None])\n",
    "        train_ds.augmentations = self.augmentations\n",
    "\n",
    "        valid_ds = AugmentedCustomDataset(mode='valid',\n",
    "                                          image_shape=self.image_shape,\n",
    "                                          files=valid_list,\n",
    "                                          augmentations=[None])\n",
    "        valid_ds.augmentations = self.augmentations\n",
    "        return train_ds, valid_ds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UBBdnHiefeDU"
   },
   "source": [
    "### `AdvancedCustomDataset`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WK7mSjJ2ftmL"
   },
   "source": [
    "В общем то, стало понятно, что обучение даже при использовании `AugmentedCustomDataset` не является эффективным, так как переобучение появляется уже на ранних этапах. Давайте доработаем `AugmentedCustomDataset` таким образом: теперь мы будем применять не фиксированный список возможных трансформаций, а будем дополнять уже существующее множество фотографий до определенного порога, и будем делать это для каждого класса. В результате работы планируется получить набор, который будет содержать одно и то же количество фотографий для каждого класса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "P6tLb1YHfrRD"
   },
   "outputs": [],
   "source": [
    "class AdvancedCustomDataset(Dataset):\n",
    "    def __init__(self, augmentate, files, ex_amount=1000, mode='train',\n",
    "                 transform=None, image_shape=(200, 200), augmentations=None):\n",
    "        \"\"\"\n",
    "        augmentate - do augmentation or not\n",
    "        ex_amount - number of photo per class\n",
    "        mode - train/valid/test\n",
    "        files - list/set with filepaths\n",
    "        transform - processing of file\n",
    "        image_shape - shape of result tensor\n",
    "        \"\"\"\n",
    "        self.mode = mode\n",
    "        self.transform = transform \\\n",
    "            if transform \\\n",
    "            else A.Resize(*image_shape)\n",
    "        self.image_shape = image_shape\n",
    "        self.ex_amount = ex_amount\n",
    "        self.check_mode = self.mode in ('train', 'valid')\n",
    "        # Labels initialization\n",
    "        labels = list(set([self.get_label(filename) for filename in files]))\n",
    "        self.le = LabelEncoder()\n",
    "        self.le.fit(labels)\n",
    "\n",
    "        # Initialize augmentation options\n",
    "        if augmentations:\n",
    "            self.augmentations = augmentations\n",
    "        else:\n",
    "            self.augmentations = (\n",
    "                A.ColorJitter(brightness=0.3,\n",
    "                              contrast=0.3,\n",
    "                              saturation=0.3),\n",
    "                A.Posterize(num_bits=2, p=1),\n",
    "                A.Sharpen(alpha=(0.9, 1.0)),\n",
    "                A.Equalize(p=1),\n",
    "                A.Rotate(limit=(-20, 20), p=1),\n",
    "                A.HorizontalFlip(p=1)\n",
    "            )\n",
    "        self.augmentations_amount = len(self.augmentations)\n",
    "        self.files = files\n",
    "        if augmentate:\n",
    "            self.files = self.augmentate()\n",
    "\n",
    "        self._len = len(self.files)\n",
    "\n",
    "    def augmentate(self):\n",
    "        labels = self.le.classes_\n",
    "        new_files = []\n",
    "        for label in labels:\n",
    "            new_files_for_label = self.augmentate_one_class(label)\n",
    "            new_files.extend(new_files_for_label)\n",
    "        return new_files\n",
    "\n",
    "    def augmentate_one_class(self, label):\n",
    "        ex_amount = self.ex_amount\n",
    "        files = self.get_class_samples(label)\n",
    "        new_files = []\n",
    "        while len(new_files) < ex_amount:\n",
    "            filename = np.random.choice(files, size=1)[0]\n",
    "            augmentations_amount = np.random.randint(low=0,\n",
    "                                                     high=self.augmentations_amount)\n",
    "            if augmentations_amount:\n",
    "                augmentations = np.random.choice(a=self.augmentations,\n",
    "                                                 size=augmentations_amount,\n",
    "                                                 replace=False)\n",
    "                augmentations = A.Compose(augmentations)\n",
    "                new_files.append((filename, augmentations))\n",
    "            else:\n",
    "                new_files.append((filename, None))\n",
    "        return new_files\n",
    "\n",
    "    def get_class_samples(self, label):\n",
    "        return [filename\n",
    "                for filename in self.files if label in filename.split('/')]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Find path to file depending on idx\n",
    "        filename, augmentations = self.files[idx]\n",
    "        img = cv2.imread(filename)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        tensor = self.transform(image=img)['image']\n",
    "        if augmentations:\n",
    "            tensor = augmentations(image=tensor)['image']\n",
    "\n",
    "        tensor = tensor / 255\n",
    "        tensor = ToTensorV2()(image=tensor)['image'].float()\n",
    "\n",
    "        if self.check_mode:\n",
    "            label = self.get_label(filename)\n",
    "            return tensor, self.encode(label)\n",
    "        else:\n",
    "            return tensor\n",
    "\n",
    "    def get_augmented_samples(self, idx):\n",
    "        \"\"\"\n",
    "        Method to get all augmentations with the same image\n",
    "        idx - index in files\n",
    "        \"\"\"\n",
    "        filename = self.files[idx][0]\n",
    "        answer = [item for item in self.files\n",
    "                  if filename == item[0]]\n",
    "        return answer\n",
    "\n",
    "    def draw_augmented_samples(self, idx):\n",
    "        files = self.get_augmented_samples(idx)\n",
    "        columns = 5\n",
    "        number = len(files)\n",
    "        if number % columns:\n",
    "            lines = int(number / columns) + 1\n",
    "        else:\n",
    "            lines = int(number / columns)\n",
    "        print(f'{number}: {lines}:{columns}')\n",
    "        plt.figure(figsize=(20, 20))\n",
    "        for idx, item in enumerate(files):\n",
    "            filename, augmentation = item\n",
    "            img = cv2.imread(filename)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            if augmentation:\n",
    "                img = augmentation(image=img)['image']\n",
    "            plt.subplot(lines, columns, idx + 1)\n",
    "            plt.imshow(img)\n",
    "\n",
    "    def get_label(self, path):\n",
    "        assert self.check_mode, \\\n",
    "            'It is not possible to get label'\n",
    "        return path.split('/')[-2]\n",
    "\n",
    "    def encode(self, str_label):\n",
    "        return self.le.transform([str_label])[0]\n",
    "\n",
    "    def decode(self, num_label):\n",
    "        return self.le.inverse_transform([num_label])[0]\n",
    "\n",
    "    def train_valid_split(self, train_size=0.9):\n",
    "        \"\"\"\n",
    "        Uniform split of files.\n",
    "\n",
    "        Returns two datasets: train_dataset and valid_dataset\n",
    "        \"\"\"\n",
    "\n",
    "        def handle_one_class(label):\n",
    "            file_list = get_class_samples(label)\n",
    "            train_set, valid_set = train_test_split(tuple(file_list),\n",
    "                                                    train_size=train_size)\n",
    "            return train_set, valid_set\n",
    "\n",
    "        def get_class_samples(label):\n",
    "            return set([filename\n",
    "                        for filename in self.files if label in filename[0].split('/')])\n",
    "\n",
    "        train_list = []\n",
    "        valid_list = []\n",
    "        labels = self.le.classes_\n",
    "\n",
    "        for label in labels:\n",
    "            cur_train_list, cur_valid_list = handle_one_class(label)\n",
    "            train_list.extend(cur_train_list)\n",
    "            valid_list.extend(cur_valid_list)\n",
    "\n",
    "        train_ds = AdvancedCustomDataset(augmentate=False, mode='train',\n",
    "                                         image_shape=self.image_shape,\n",
    "                                         files=train_list)\n",
    "        train_ds.augmentations = self.augmentations\n",
    "\n",
    "        valid_ds = AdvancedCustomDataset(augmentate=False, mode='valid',\n",
    "                                         image_shape=self.image_shape,\n",
    "                                         files=valid_list)\n",
    "        valid_ds.augmentations = self.augmentations\n",
    "        return train_ds, valid_ds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8tPpz2ClN7wH"
   },
   "source": [
    "### Сравнение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2zcvuJ9EF7Tv"
   },
   "outputs": [],
   "source": [
    "def memory_counter(ex, all = False):\n",
    "    \"\"\"\n",
    "    Memory counter for existing class instance\n",
    "    all - count all variables and methods in ex, else exclude __methods__\n",
    "    \"\"\"\n",
    "    mem = 0\n",
    "    if all:\n",
    "        for key, val in ex.__dict__.items():\n",
    "            mem += sys.getsizeof(val)\n",
    "        return mem\n",
    "    else:\n",
    "        for key, val in ex.__dict__.items():\n",
    "            if key.startswith('_'):\n",
    "                continue\n",
    "            else:\n",
    "                mem += sys.getsizeof(val)\n",
    "        return mem\n",
    "\n",
    "def dataset_metric(cls, print_info = True, **kwargs):\n",
    "    \"\"\"\n",
    "    Comparing of classes with datasets: init, traverse, memory\n",
    "    \"\"\"\n",
    "    print(f'Class name: {cls.__name__}')\n",
    "    begin = time.time()\n",
    "    ex = cls(**kwargs)\n",
    "    to_init = time.time() - begin\n",
    "    print('Time to init: {:.5f} s'.format(to_init))\n",
    "    begin = time.time()\n",
    "    for _ in ex:\n",
    "        pass\n",
    "    to_traverse = time.time() - begin\n",
    "    print('Time to traverse: {:.5f} s'.format(to_traverse))\n",
    "    memory = memory_counter(ex)\n",
    "    info = '\\n'.join(['Memory: {} bytes = {:.3f} MB',\n",
    "                    'Total elements: {} elements',\n",
    "                    'Mean iteration time: {:.4f} s',\n",
    "                    'Mean memory usage per element: {:.4f} bytes',\n",
    "                     '']).format(memory, memory / 10 ** 6, \n",
    "                                 len(ex), \n",
    "                                 to_traverse / len(ex),\n",
    "                                 memory / len(ex))\n",
    "    if print_info:\n",
    "        print(info)\n",
    "    \n",
    "    d = (cls.__name__, to_init, to_traverse, memory)\n",
    "    del ex\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JuD_S8CGNiyn",
    "outputId": "0f6d8038-a724-4f2a-922b-ed29081fb1a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class name: AdvancedCustomDataset\n",
      "Time to init: 22.53049 s\n",
      "Time to traverse: 1930.73612 s\n",
      "Memory: 1764466 bytes = 1.764 MB\n",
      "Total elements: 210000 elements\n",
      "Mean iteration time: 0.0092 s\n",
      "Mean memory usage per element: 8.4022 bytes\n",
      "\n"
     ]
    }
   ],
   "source": [
    "advds_metric = dataset_metric(AdvancedCustomDataset, augmentate = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bXEd3l6hPayL",
    "outputId": "65b99c19-91ae-492c-92b9-399667a8434d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class name: CustomDataset\n",
      "Time to init: 0.00100 s\n",
      "Time to traverse: 126.87075 s\n",
      "Memory: 84378 bytes = 0.084 MB\n",
      "Total elements: 10515 elements\n",
      "Mean iteration time: 0.0121 s\n",
      "Mean memory usage per element: 8.0245 bytes\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cds_metric = dataset_metric(CustomDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IBiLKY-A0YX7",
    "outputId": "76de6c21-93ed-4e00-a0a7-5e452b8a2bed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class name: FastDataset\n",
      "Time to init: 131.19805 s\n",
      "Time to traverse: 3.40911 s\n",
      "Memory: 170610 bytes = 0.171 MB\n",
      "Total elements: 10515 elements\n",
      "Mean iteration time: 0.0003 s\n",
      "Mean memory usage per element: 16.2254 bytes\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fds_metric = dataset_metric(FastDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5xNRbcfM7gy_",
    "outputId": "d05e6566-9124-4ea7-fdbd-487b2ce75fa0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class name: AugmentedCustomDataset\n",
      "Time to init: 0.020332813262939453\n",
      "Time to traverse: 1068.542881011963\n",
      "Memory: 6457296 bytes = 6.457 MB\n",
      "Total elements: 73605 elements\n",
      "Mean iteration time: 0.015\n",
      "Mean memory per element: 87.729 bytes\n"
     ]
    }
   ],
   "source": [
    "acds_metric = dataset_metric(AugmentedCustomDataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mns_79Kqatr6"
   },
   "source": [
    "### Выводы\n",
    "Тут надо подумать и выбрать, пока буду юзать Fast.\n",
    "\n",
    "Стоит еще заметить вот что: при работе с `torchvision.datasets.DatasetFolder` у нас классификация происходит иначе, нежели в остальных классах. Соответственно, если обучить сетку, а потом поменять тип используемого датасета, то будет плохо. Поэтому на этом мы прощаемся этой штукой. Не очень грустно, потому что в сравнении с другими вариантами она не сказать что превосходит по времени/памяти.\n",
    "\n",
    "В перспективе, конечно, правильнее будет использовать `CustomDataset`, потому что при расширении датасета для `FastDataset` может банально не хватить памяти. Пока же, мы будем использовать `FastDataset`, и если что, добавлю возможность переключения на `CustomDataset`.\n",
    "\n",
    "Но как выяснилось, данных слишком мало, поэтому их пришлось аугментировать. Создал два новых класса: `AugmentedCustomDataset` - аналог `CustomDataset` с возможностью аугментации, и `AugmentedFastDataset` - аналог `FastDataset` с возможностью аугментации.\n",
    "\n",
    "Далее, будем использовать `AugmentedCustomDataset`, потому что быстрый аналог банально перестал влезать в память. Но придется потерять во времени..("
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YrEARZntOa-v"
   },
   "source": [
    "Также, во время прогонки `AdvancedCustomDataset` выяснилось, что методы аугментации из `torchvision.transforms` работают несколько дольше, нежели аналоги из `albumentations`. Поэтому в `AdvancedCustomDataset` будут использоваться методы модуля `albumentations`.\n",
    "\n",
    "А еще, оказалось, что считывание через `cv2.imread` работает быстрее,чем `PIL.Image.open`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fS1ysaaPZdkh"
   },
   "source": [
    "## Разбиение данных\n",
    "\n",
    "Это я выделил в отдельный раздельчик, причина, как по мне, существенная: картинок очень мало (по 50 на класс), классов очень много (210) и хотелось бы проконтроллировать, чтоб в тренировочной выборке был баланс классов. Я думаю, что в тренировочную выборку мы закинем 90% (для начала, дальше видно будет). Возможно, придется обучать на всей выборке, а потом валидиться на каком то подмножестве тренировочной выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "sl2RxSztsh3n"
   },
   "outputs": [],
   "source": [
    "def make_loaders(ds_cls, train_size, train_bs, valid_bs, ds_params):\n",
    "    \"\"\"\n",
    "    ds_cls - class of using dataset\n",
    "    Return two DataLoaders: train and valid\n",
    "    \"\"\"\n",
    "\n",
    "    ds = ds_cls(**ds_params)\n",
    "    train_ds, valid_ds = ds.train_valid_split(train_size = train_size)\n",
    "\n",
    "    train_dl = DataLoader(train_ds, batch_size = train_bs,\n",
    "                          shuffle = True, num_workers = 1)\n",
    "\n",
    "    valid_dl = DataLoader(valid_ds, batch_size = valid_bs,\n",
    "                          shuffle = False, num_workers = 1)\n",
    "    \n",
    "    return train_dl, valid_dl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_wGXQ3ejatRj"
   },
   "source": [
    "## Цикл обучения с валидацией"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "yDnzHsDOwAT9"
   },
   "outputs": [],
   "source": [
    "def train_valid(model, train_dl, valid_dl,\n",
    "                opt_cls, opt_params, loss_fn, \n",
    "                metric_fn, max_epochs:int,\n",
    "                device,\n",
    "                scheduler_cls = None, scheduler_params = None):\n",
    "    \"\"\"\n",
    "    Train and validation cycle.\n",
    "\n",
    "    train_dl - DataLoader with train data\n",
    "    valid_dl - DataLoader with valid data\n",
    "    opt - optimizer\n",
    "    loss_fn - loss function\n",
    "    metric_fn - metric function to evaluate model\n",
    "    max_epochs - epochs to training and validation\n",
    "    scheduler_cls - class of scheduler\n",
    "    \"\"\"\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    train_metric = []\n",
    "    valid_metric = []\n",
    "    \n",
    "    def print_loss_metric_info(train_loss = train_losses, \n",
    "                               valid_loss = valid_losses,\n",
    "                               train_metric = train_metric, \n",
    "                               valid_metric = valid_metric):\n",
    "        \"\"\"\n",
    "        Logger function\n",
    "        \"\"\"\n",
    "        template = '\\n'.join(['',\n",
    "                              'Losses on train: {}',\n",
    "                              'Losses on valid: {}',\n",
    "                              'Metric on train: {}',\n",
    "                              'Metric on valid: {}'])\n",
    "        print(template.format(train_loss,\n",
    "                               valid_loss,\n",
    "                               train_metric,\n",
    "                               valid_metric))\n",
    "\n",
    "    # Optimizer initialization\n",
    "    opt = opt_cls(params = model.parameters(), \n",
    "                  **opt_params)\n",
    "    \n",
    "    # Scheduler initialization\n",
    "    if scheduler_cls:\n",
    "        scheduler = scheduler_cls(optimizer = opt,\n",
    "                                  **scheduler_params)\n",
    "    else:\n",
    "        scheduler = None\n",
    "    model.to(device)\n",
    "    train_time = 0\n",
    "    valid_time = 0\n",
    "    for epoch in tqdm(range(max_epochs), desc = 'Epoch'):\n",
    "    # Training cycle\n",
    "        model.train()\n",
    "        train_losses_epoch = []\n",
    "        train_metric_epoch = []\n",
    "        print_loss_metric_info()\n",
    "        begin_time = time.time()\n",
    "        for x, y in tqdm(train_dl):\n",
    "            opt.zero_grad()\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            output = model(x)\n",
    "            y_pred = torch.argmax(output, dim = -1)\n",
    "\n",
    "            loss = loss_fn(output, y)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            metric_value = metric_fn(y.to('cpu'), y_pred.to('cpu'), average = 'macro')\n",
    "            train_metric_epoch.append(metric_value)\n",
    "            train_losses_epoch.append(loss.item())\n",
    "        train_time += (time.time() - begin_time)\n",
    "        train_losses.append(np.mean(train_losses_epoch))\n",
    "        train_metric.append(np.mean(train_metric_epoch))\n",
    "\n",
    "    # Valid cycle\n",
    "        model.eval()\n",
    "        valid_losses_epoch = []\n",
    "        valid_metric_epoch = []\n",
    "        print_loss_metric_info()\n",
    "        begin_time = time.time()\n",
    "        with torch.no_grad():\n",
    "            for x, y in tqdm(valid_dl):\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                output = model(x)\n",
    "                y_pred = torch.argmax(output, dim = -1)\n",
    "\n",
    "                loss = loss_fn(output, y)\n",
    "\n",
    "                metric_value = metric_fn(y.to('cpu'), y_pred.to('cpu'), average = 'macro')\n",
    "                valid_losses_epoch.append(loss.item())\n",
    "                valid_metric_epoch.append(metric_value)\n",
    "\n",
    "        valid_metric.append(np.mean(valid_metric_epoch))\n",
    "        valid_losses.append(np.mean(valid_losses_epoch))\n",
    "        valid_time += (time.time() - begin_time)\n",
    "\n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "\n",
    "        clear_output()\n",
    "\n",
    "    return train_losses, valid_losses, train_metric, valid_metric, train_time, valid_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rwn8hIogbgxH"
   },
   "source": [
    "## Написание моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0gXwH2kwbncZ"
   },
   "source": [
    "В качестве моделей мы будем использовать сверточные нейронные сети и различные ансамбли."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q7GbaDHtpIWC"
   },
   "source": [
    "### Сверточные сети\n",
    "\n",
    "Для перебора архитектур не будем заводить отдельного класса, а напишем один раз шаблон и будем его менять прям в коде, потому что далее все равно будет выполняться сохранение моделей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "uNHVGjg0ziL9"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, n_classes = len(labels)):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.n_classes = n_classes\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 8, 7)\n",
    "        self.c_act1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(8, 32, 3)\n",
    "        self.c_act2 = nn.ReLU()\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3)\n",
    "        self.c_act3 = nn.ReLU()\n",
    "        self.pool3 = nn.MaxPool2d(2)\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(64, 128, 3)\n",
    "        self.c_act4 = nn.ReLU()\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "\n",
    "        self.conv5 = nn.Conv2d(128, 256, 3)\n",
    "        self.c_act5 = nn.ReLU() \n",
    "        self.pool5 = nn.MaxPool2d(2)\n",
    "\n",
    "        self.conv6 = nn.Conv2d(256, 256, 3)\n",
    "        self.c_act6 = nn.ReLU()\n",
    "\n",
    "        self.flattener = nn.Flatten()\n",
    "\n",
    "        self.bn3 = nn.BatchNorm1d(9216)\n",
    "\n",
    "        self.linear1 = nn.Linear(9216, 4096)\n",
    "        self.l_act1 = nn.ReLU()\n",
    "\n",
    "        self.linear2 = nn.Linear(4096, 1024)\n",
    "        self.l_act2 = nn.ReLU()\n",
    "\n",
    "        self.linear3 = nn.Linear(1024, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(self.c_act1(self.conv1(x)))\n",
    "        \n",
    "        x = self.c_act2(self.conv2(x))\n",
    "        x = self.bn1(x)\n",
    "        \n",
    "        x = self.pool3(self.c_act3(self.conv3(x)))\n",
    "        \n",
    "        x = self.c_act4(self.conv4(x))\n",
    "        x = self.bn2(x)\n",
    "        \n",
    "        x = self.pool5(self.c_act5(self.conv5(x)))\n",
    "        \n",
    "        x = self.c_act6(self.conv6(x))\n",
    "\n",
    "        x = self.flattener(x)\n",
    "        x = self.bn3(x)\n",
    "        \n",
    "        x = self.l_act1(self.linear1(x))\n",
    "        \n",
    "        x = self.l_act2(self.linear2(x))\n",
    "        \n",
    "        x = self.linear3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "eNsTMHN5MA2i"
   },
   "outputs": [],
   "source": [
    "def train_valid_save(model, artifact_config,\n",
    "                     preprocess_config,\n",
    "                     train_config):\n",
    "    \n",
    "    art = wandb.Artifact(**artifact_config)\n",
    "    exp_name = artifact_config['name']\n",
    "    print('Making dataloaders...')\n",
    "    train_dl, valid_dl = make_loaders(**preprocess_config)\n",
    "    clear_output()\n",
    "    train_losses, valid_losses, train_metric, valid_metric, train_time, valid_time = train_valid(\n",
    "        model = model,\n",
    "        train_dl = train_dl,\n",
    "        valid_dl = valid_dl,\n",
    "        **train_config\n",
    "    )\n",
    "\n",
    "    # Saving model\n",
    "    torch.save(model.state_dict(),\n",
    "                './models/models/' + exp_name + '.pth')\n",
    "\n",
    "    epochs = train_config['max_epochs']\n",
    "    for_table = list(zip(range(1, epochs + 1), \n",
    "                         train_losses,\n",
    "                         valid_losses,\n",
    "                         train_metric,\n",
    "                         valid_metric)) \n",
    "    \n",
    "    tabled_cfg = wandb.Table(\n",
    "        columns = ['Epoch', 'Train losses', 'Valid losses', 'Train score', 'Valid score'],\n",
    "        data = for_table\n",
    "    )\n",
    "\n",
    "    # Model state dict\n",
    "    art.add_file('./models/models/' + exp_name + '.pth',\n",
    "                 name = 'state_dict.pth')\n",
    "    \n",
    "    # Losses and metrics\n",
    "    art.add(tabled_cfg, 'Losses and scores table')\n",
    "\n",
    "    # Add result description\n",
    "    result_config = {'Train time': train_time,\n",
    "                     'Valid time': valid_time,\n",
    "                     'Device': device}\n",
    "\n",
    "    # Add configuration\n",
    "    common_config = {'Preprocess': preprocess_config,\n",
    "                     'Training': train_config,\n",
    "                     'Resulting': result_config}\n",
    "\n",
    "    art.metadata = common_config\n",
    "\n",
    "    x = next(model.modules())\n",
    "    with open('./models/desc/' + exp_name + '.txt', 'w') as f:\n",
    "        f.write(str(x))\n",
    "\n",
    "    art.add_file('./models/desc/' + exp_name + '.txt',\n",
    "                 name = 'desc.txt')\n",
    "\n",
    "    wandb.log_artifact(art)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lh802qOeGvRi",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "dataset_config = {\n",
    "    'augmentate': True,\n",
    "    'image_shape': (100, 100),\n",
    "    'ex_amount': 2000\n",
    "}\n",
    "\n",
    "preprocess_config = {\n",
    "    'ds_cls': AdvancedCustomDataset,\n",
    "    'ds_params': dataset_config,\n",
    "    'train_bs': 128,\n",
    "    'valid_bs': 256,\n",
    "    'train_size': 0.9\n",
    "}\n",
    "\n",
    "train_config = {\n",
    "    'opt_cls': torch.optim.Adam,\n",
    "    'loss_fn': nn.CrossEntropyLoss(),\n",
    "    'metric_fn': f1_score,\n",
    "    'max_epochs': 10,\n",
    "    'opt_params': {\n",
    "        'lr': 5e-4\n",
    "    },\n",
    "    'scheduler_cls': torch.optim.lr_scheduler.StepLR,\n",
    "    'scheduler_params': {\n",
    "        'step_size': 4,\n",
    "        'gamma': 0.55\n",
    "    },\n",
    "    'device': device\n",
    "}\n",
    "\n",
    "artifact_config = {\n",
    "    'name': 'CNN_v.1',\n",
    "    'type': 'model',\n",
    "    'description':\n",
    "    '''Using advanced dataset with 3k images per class;\n",
    "    Edited train function: now saving model with the highest metric on valid dataset\n",
    "    '''\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 219
    },
    "id": "aI70rjr9QrjM",
    "outputId": "9ab0bafa-62d0-45de-aeeb-a6fc23b16022",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_valid_save(model = model,\n",
    "                 artifact_config = artifact_config,\n",
    "                 preprocess_config = preprocess_config,\n",
    "                 train_config = train_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "id": "mpHbAJysMGPv",
    "outputId": "2e4e3988-27ae-4077-cf47-c5dfdd15a827"
   },
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "SnSm8eSra48Z",
    "8dyv0_7gbQyx",
    "Q547p3nH9Llz",
    "lhrc_O1H6wGT",
    "62u_hQUT7Dvb",
    "8tPpz2ClN7wH",
    "uD8IxRDrZNqC",
    "iFtWTJNykwdP",
    "GILf8neHv0gE",
    "Q7XNEgDVwbTA"
   ],
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
